{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn4cEuAeRLdwqStJxoBp/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadikaVER/xml_parser/blob/main/SteelEye_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Packages\n",
        ">- boto3\n"
      ],
      "metadata": {
        "id": "4zE1fC4hF9zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "Umfnhbcf5u-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0380661-20d1-4a25-bf30-933a23724be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.82)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.82 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.82)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.82->boto3) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.82->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.82->boto3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install s3fs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMYlMQ7s1l5",
        "outputId": "3ee0f967-e174-41b4-ca5a-7aa6b6df8308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.7/dist-packages (2022.8.2)\n",
            "Requirement already satisfied: fsspec==2022.8.2 in /usr/local/lib/python3.7/dist-packages (from s3fs) (2022.8.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from s3fs) (3.8.1)\n",
            "Requirement already satisfied: aiobotocore~=2.4.0 in /usr/local/lib/python3.7/dist-packages (from s3fs) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.4.0->s3fs) (1.14.1)\n",
            "Requirement already satisfied: aioitertools>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.4.0->s3fs) (0.11.0)\n",
            "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.4.0->s3fs) (1.27.59)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "2G9CHrYcqNDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkVaN6jepIZ5",
        "outputId": "f3a87a7a-a038-499d-f891-31252ad72eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/My Drive/dataset/Assignment/internshala/SteelEye/\""
      ],
      "metadata": {
        "id": "_qwZQZ4jpYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages\n",
        "> * pandas : For creating csv files\n",
        "> * xml.etree.ElementTree : To parse XML\n",
        "> * os : for file path\n",
        "> * shutil: for unzipping files  \n",
        "> * boto3: for aws s3 bucket operations\n",
        "> * logging: for logging "
      ],
      "metadata": {
        "id": "NJy7Pt3NqRKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import shutil\n",
        "import boto3\n",
        "import logging as log\n",
        "import urllib\n",
        "import pprint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "y6YHVmt4qMDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse the given source xml file and store its value in .csv file "
      ],
      "metadata": {
        "id": "BHNVyiHYqUB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_source_file(path,filename):\n",
        "  '''\n",
        "     Parses the source xml file and create the parsed result in structured format.\n",
        "     Param(s):\n",
        "        filename (str): xml filename\n",
        "        path     (str): source path   \n",
        "  '''\n",
        "  try:\n",
        "    logg.info(\"Loading Source xml file ...\")\n",
        "    tree=ET.parse(path+filename)\n",
        "    root=tree.getroot()\n",
        "    logg.info(\"Parsing Source xml file ...\")\n",
        "    check,link,pub_date,rt,pubinsfl,id,filename,file_type,version,timestamp=[],[],[],[],[],[],[],[],[],[]\n",
        "    logg.info(\"Extracting information within doc tag ...\")\n",
        "    for child in root.iter():\n",
        "      for key,value in child.attrib.items():\n",
        "        if value ==\"checksum\":\n",
        "          check.append(child.text)\n",
        "        if value=='download_link':\n",
        "          link.append(child.text)\n",
        "        if value==\"publication_date\":\n",
        "          pub_date.append(child.text)\n",
        "        if value== \"_root_\":\n",
        "          rt.append(child.text)\n",
        "        if value==\"published_instrument_file_id\":\n",
        "          pubinsfl.append(child.text)\n",
        "        if value==\"id\":\n",
        "          id.append(child.text)\n",
        "        if value==\"file_name\":\n",
        "          filename.append(child.text)\n",
        "        if value==\"file_type\":\n",
        "          file_type.append(child.text)\n",
        "        if value==\"_version_\":\n",
        "          version.append(child.text)\n",
        "        if value==\"timestamp\":\n",
        "          timestamp.append(child.text)\n",
        "\n",
        "    logg.info(\"Storing the extracted information from Source xml file to demo_xml_parsed file in tabular format with .csv extension ...\")\n",
        "    df=pd.DataFrame()\n",
        "    df[\"Cheksum\"]=check\n",
        "    df[\"Link\"]=link\n",
        "    df[\"Publication_date\"]=pub_date\n",
        "    df[\"Root\"]=rt\n",
        "    df[\"Publication_inst_file\"]=pubinsfl\n",
        "    df[\"ID\"]=id\n",
        "    df[\"Filename\"]=filename\n",
        "    df[\"File_type\"]=file_type\n",
        "    df[\"Version\"]=version\n",
        "    df[\"Timestamp\"]=timestamp\n",
        "\n",
        "    logg.info(\"Saving parsed  file to google drive ...\")\n",
        "    df.to_csv(path+\"demo_xml_parsed.csv\",sep=\",\",index=False)  \n",
        "  except Exception as e:\n",
        "    logg.error(f\"Error : {str(e)}\")\n"
      ],
      "metadata": {
        "id": "5RR7nyBQILYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GE9LSUkqVgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and save the files to drive whose file type is DLTINS from the links given in parsed file.\n",
        "    "
      ],
      "metadata": {
        "id": "WM-R-RHv1Jeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_files_from_link(path):\n",
        "  '''\n",
        "  1. Extract the zip files from links and save them to google drive\n",
        "  2. unzip the saved files.\n",
        "\n",
        "  Params: \n",
        "    path  (str): file path\n",
        "  '''\n",
        "  try :\n",
        "    # load the parsed demo_xml_parsed.csv file\n",
        "    df=pd.read_csv(path+\"demo_xml_parsed.csv\",sep=\",\")\n",
        "    # select only those file whose type is DLTINS\t\n",
        "    df=df[df[\"File_type\"]==\"DLTINS\"]\n",
        "    i=0\n",
        "    logg.info(\"Extract the files from link...\")\n",
        "    for url in df[\"Link\"].tolist():\n",
        "      file_name = path+'myzip'+str(i)+'.zip'\n",
        "      logg.info(\"Saving file  and unzipping: \"+url.split(\"/\")[-1].split(\".\")[0]+\" to drive\")\n",
        "      with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
        "        shutil.copyfileobj(response, out_file)\n",
        "      shutil.unpack_archive(path+'myzip'+str(i)+'.zip', path+\"data_file\")   \n",
        "      i+=1  \n",
        "  except Exception as e :\n",
        "         logg.error(f\"Error : {str(e)}\") \n",
        "\n"
      ],
      "metadata": {
        "id": "Bz2njFcyNjyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_Mj9sdqrySY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse the above extracted DLTINS xml files and  store the following information into .csv file .\n",
        ">- ID\n",
        ">- FullNm\n",
        ">- ClssfctnTp\n",
        ">- CmmdtyDerivInd\n",
        ">- NtnlCcy\n",
        ">- Issr"
      ],
      "metadata": {
        "id": "qs_TjM0XGysU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_data(path):\n",
        "  '''\n",
        "  Extract data from above stated attributes and store the results in tabular format \n",
        "  as .csv file\n",
        "\n",
        "  Params:\n",
        "  path (str): file path (for storing and loading)\n",
        "  '''\n",
        "  try:\n",
        "    # extract all the files that startswith DLTINS\n",
        "    files=[f for f in os.listdir(path+\"data_file\") if f.startswith(\"DLTINS\")]\n",
        "  \n",
        "    df=pd.DataFrame()\n",
        "    id,nm,cls,cmd,nt,issr=[],[],[],[],[],[]\n",
        "    for fl in files:\n",
        "      tree=ET.parse(path+\"data_file/\"+fl)\n",
        "      root=tree.getroot()\n",
        "      for child in root.iter():\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}Id\":\n",
        "          if len(child.text)>4:\n",
        "            id.append(child.text)\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}FullNm\":\n",
        "          nm.append(child.text)\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}ClssfctnTp\":\n",
        "          cls.append(child.text)\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}CmmdtyDerivInd\":\n",
        "          cmd.append(child.text)\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}NtnlCcy\":\n",
        "          nt.append(child.text)\n",
        "        if child.tag==\"{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}Issr\":\n",
        "          issr.append(child.text)\n",
        "    \n",
        "    df[\"ID\"]=id\n",
        "    df[\"FullName\"]=nm\n",
        "    df[\"ClssfctnTp\"]=cls\n",
        "    df[\"CmmdtyDerivlnd\"]=cmd\n",
        "    df[\"NtnlCcy\"]=nt\n",
        "    df[\"Issr\"]=issr\n",
        "    df.to_csv(path+\"final_file.csv\",sep=\",\",index=False)\n",
        "\n",
        "  except Exception as e:\n",
        "    logg.error(f\"Error : {str(e)}\") "
      ],
      "metadata": {
        "id": "0v-pwrNZSr_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload final csv file to aws s3\n"
      ],
      "metadata": {
        "id": "3ZEtCSf8cJ7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aws_file_upload(path,bucket_name,filename):\n",
        "  '''\n",
        "  Upload the final file to AWS S3 bucket\n",
        "\n",
        "  Params:\n",
        "\n",
        "  path (str) : file path\n",
        "  region_name (str): Region name of s3 bucket is hosted\n",
        "  access_key  (str): AWS Access key id\n",
        "  secret_key  (str): AWS secret key\n",
        "  bucket_name  (str): name of bucket where to store final file\n",
        "  filename     (str): name of the file its shoud be on bucket\n",
        "\n",
        "  returns :\n",
        "    True : if loads sucessfully   \n",
        "  '''\n",
        "\n",
        "  s3 = boto3.client('s3')\n",
        "  s3=boto3.resource(\n",
        "                  service_name='s3',\n",
        "                 \n",
        "                  )\n",
        "  \n",
        "   \n",
        "  logg.info(\"Uploading the final file to s3 Bucket\")  \n",
        "  # upload file to s3 bucket\n",
        "  s3.Bucket(bucket_name).upload_file(Filename=path+filename,Key=filename)\n",
        "    \n",
        "    \n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "SZSSZDxeWrIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "z3ZYTUm5hCDt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-1I5Tn7s8gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Note :\n",
        "## âš› For aws credentials you have to create user , so that can load and access file in AWS S3 and for this [ click link ](https://www.youtube.com/watch?v=JKlOlDFwsao)"
      ],
      "metadata": {
        "id": "uyjUOSDX02zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"################\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"#######################\""
      ],
      "metadata": {
        "id": "tuQ7qSpS2ye-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  log.basicConfig()\n",
        "\n",
        "  log.root.setLevel(log.NOTSET)\n",
        "\n",
        "  log.basicConfig(level=log.NOTSET)\n",
        "\n",
        "  handle = \"xml_parser\"\n",
        "  logger1 = log.getLogger(handle)\n",
        "  \n",
        "  logg = log.getLogger(__name__)\n",
        "\n",
        "  source_filename=\"demo.xml\"\n",
        "\n",
        "\n",
        "  parse_source_file(path,source_filename)\n",
        "  logg.info(\"Step:1 Parse Source file completed \")\n",
        "\n",
        "\n",
        "  extract_files_from_link(path)\n",
        "  logg.info(\"Step:2 Extract , save and unzip xml file from link completed\")\n",
        "\n",
        "\n",
        "  xml_data(path)\n",
        "  logg.info(\"Step:3 Parse Extracted files and convert into .csv file completed\")\n",
        "\n",
        "\n",
        " \n",
        "  # enter the aws credentials\n",
        "  region_name='us-east-1'\n",
        "  bucket_name='xml2data'\n",
        "  filename=\"final_file.csv\"\n",
        "\n",
        "  aws_file_upload(path,bucket_name,filename)\n",
        " \n",
        "  logg.info(\"Step:4 Upload to aws s3 Bucket completed\")\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2my5uZvYf5d",
        "outputId": "0f77147e-a2a7-4b18-a5eb-299ecbd45589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Loading Source xml file ...\n",
            "INFO:__main__:Parsing Source xml file ...\n",
            "INFO:__main__:Extracting information within doc tag ...\n",
            "INFO:__main__:Storing the extracted information from Source xml file to demo_xml_parsed file in tabular format with .csv extension ...\n",
            "INFO:__main__:Saving parsed  file to google drive ...\n",
            "INFO:__main__:Step:1 Parse Source file completed \n",
            "INFO:__main__:Extract the files from link...\n",
            "INFO:__main__:Saving file  and unzipping: DLTINS_20210117_01of01 to drive\n",
            "INFO:__main__:Saving file  and unzipping: DLTINS_20210119_01of02 to drive\n",
            "INFO:__main__:Saving file  and unzipping: DLTINS_20210119_02of02 to drive\n",
            "INFO:__main__:Saving file  and unzipping: DLTINS_20210118_01of01 to drive\n",
            "INFO:__main__:Step:2 Extract , save and unzip xml file from link completed\n",
            "INFO:__main__:Step:3 Parse Extracted files and convert into .csv file completed\n",
            "INFO:__main__:Step:4 Upload to aws s3 Bucket completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-a0hSMsaejM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}